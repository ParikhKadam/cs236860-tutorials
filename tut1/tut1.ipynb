{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Convolutions - implementation and examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "Given two singals $f\\left(x\\right)$ and $h\\left(x\\right)$, their convolutions is defined as\n",
    "$$\\left(h*f\\right)\\left(x\\right)=\\int_{\\mathbb{R}^n}h\\left(x-y\\right)f\\left(y\\right)dy=\\int_{\\mathbb{R}^n}\\tau_{-x}h\\left(-y\\right)f\\left(y\\right)dy$$\n",
    "\n",
    "In the discrete case we define\n",
    "$$\\left(h*f\\right)\\left[n\\right]=\\sum_{k=-\\infty}^{\\infty}h\\left[n-k\\right]f\\left[k\\right]$$\n",
    "\n",
    "Although convolution is commutative, we will usually refer to $f$ as the signal and call $h$ the kernel or the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D convolution\n",
    "Let's see a few examples:\n",
    "\n",
    "![first example](./1d1.gif)\n",
    "\n",
    "![second example](./1d2.gif)\n",
    "\n",
    "Let's start coding. We will import a the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a very primitive implementation of convolution on 1D. It implements the core functionality of the function `scipy.signal.convolve`. However this is a specific case where the parameter `size='valid'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conv1d(a, b):\n",
    "    c = np.zeros(a.size + b.size - 1)\n",
    "    for i in np.arange(a.size):\n",
    "        for j in np.arange(b.size):\n",
    "            c[i + j] += a[i] * b[j]\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see an example:\n",
    "* Consider a constant signal with 100 sample points which is contaminated by additive gaussian noise.\n",
    "* Consider a uniform filter which is initalized to ones and then normalized. We normalize our kernels just so that we end up with a similar range of values as in the original signal. Try playing with the value of `KERNEL_SIZE` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_SIZE = 100\n",
    "KERNEL_SIZE = 11\n",
    "\n",
    "signal = np.ones(SIGNAL_SIZE)\n",
    "noise = np.random.randn(SIGNAL_SIZE)\n",
    "noisy_signal = signal + noise\n",
    "kernel = np.ones(KERNEL_SIZE)\n",
    "kernel /= sum(kernel)\n",
    "convolved_signal = my_conv1d(noisy_signal, kernel)\n",
    "\n",
    "plt.plot(signal)\n",
    "plt.plot(noisy_signal)\n",
    "plt.plot(convolved_signal)\n",
    "plt.legend(('signal', 'noisy signal', 'convolved signal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciruclant matrices are matrices where each row/column is a ciruclant permutation of the previous one:\n",
    "$$\n",
    "\\mathbf{H}=\n",
    "\\left(\\begin{array}{cc} \n",
    "h_0 & h_1 & \\dots & h_{n-1} \\\\\n",
    "h_{n-1} & h_0 && h_{n-2} \\\\\n",
    "\\vdots \\\\\n",
    "h_1 & h_2 && h_0\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Using the kernel $\\mathbf{h}$ as the rows of $\\mathbf{H}$ yields the appropriate convolution operator. Let's verify it.\n",
    "\n",
    "First we'll create the circulant matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original kernel:')\n",
    "print(kernel)\n",
    "\n",
    "full_kernel = np.zeros(SIGNAL_SIZE)\n",
    "full_kernel[:KERNEL_SIZE] = kernel\n",
    "full_kernel = np.roll(full_kernel, -(KERNEL_SIZE // 2))\n",
    "print('full kernel:')\n",
    "print(full_kernel[:KERNEL_SIZE])\n",
    "print('...')\n",
    "print(full_kernel[-KERNEL_SIZE:])\n",
    "\n",
    "circulant_matrix = scipy.linalg.circulant(full_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convolve with our new matrix and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circulantly_convolved_signal = circulant_matrix.dot(noisy_signal)\n",
    "plt.plot(signal)\n",
    "plt.plot(noisy_signal)\n",
    "plt.plot(convolved_signal[KERNEL_SIZE // 2 : -(KERNEL_SIZE // 2)])\n",
    "plt.plot(circulantly_convolved_signal)\n",
    "plt.legend(('signal', 'noisy signal', 'convolved signal', 'circulantly convolved signal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D convolution\n",
    "![illustration](./2d.gif)\n",
    "\n",
    "Now we will implement a primitive asymmetrical implementation of conv2d. Basically we go over each pixel, consider it's neighborhood and multiply element-wise with the kernel. This gives us the pixel value of the convolved image with the given kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conv2d(image, kernel, normalize=False):\n",
    "    # fetch the dimensions for iteration over the pixels and weights\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    kernel_shift_y = kernel_height // 2\n",
    "    kernel_shift_x = kernel_width // 2\n",
    "\n",
    "    # prepare the output array\n",
    "    filtered = np.zeros_like(image)\n",
    "    \n",
    "    # iterate over each (x, y) pixel in the image\n",
    "    for y in range(image_height):\n",
    "        for x in range(image_width):\n",
    "            weighted_pixel_sum = 0\n",
    "\n",
    "            # Iterate over each weight at (kx, ky) in the kernel defined above ...\n",
    "            # We interpret the kernel weights in a way that the 'central' weight is at (0, 0);\n",
    "            # so the coordinates in the kernel are:\n",
    "            #\n",
    "            #  [ (-1,-1),  (0,-1),  (1,-1)\n",
    "            #    (-1, 0),  (0, 0),  (1, 0)\n",
    "            #    (-1, 1),  (0, 1),  (1, 1)\n",
    "            #\n",
    "            # This way, the pixel at image[y,x] is multiplied with the kernel[0,0]; analogous,\n",
    "            # image[y-1,x] is multiplied with kernel[-1,0] etc.\n",
    "            # The filtered pixel is then the sum of these, so that\n",
    "            #\n",
    "            #   weighted_pixel_sum = image[y-1,x-1] * kernel[-1,-1] +\n",
    "            #                        image[y-1,x  ] * kernel[-1, 0] +\n",
    "            #                        image[y-1,x+1] * kernel[-1, 1] +\n",
    "            #                        image[y,  x-1] * kernel[ 0, 1] +\n",
    "            #                        image[y,  x  ] * kernel[ 0, 0] +\n",
    "            #                        etc.\n",
    "\n",
    "            for ky in range(-kernel_shift_y, kernel_shift_y + 1):\n",
    "                for kx in range(-kernel_shift_x, kernel_shift_x + 1):\n",
    "                    pixel = 0\n",
    "                    pixel_y = y - ky\n",
    "                    pixel_x = x - kx\n",
    "\n",
    "                    # boundary check: all values outside the image are treated as zero.\n",
    "                    # this is a definition and implementation dependent\n",
    "                    if (pixel_y >= 0) and (pixel_y < image_height) and (pixel_x >= 0) and (pixel_x < image_width):\n",
    "                        pixel = image[pixel_y, pixel_x]\n",
    "\n",
    "                    # get the weight at the current kernel position\n",
    "                    # (also un-shift the kernel coordinates into the valid range for the array)\n",
    "                    weight = kernel[ky + kernel_shift_y, kx + kernel_shift_x]\n",
    "\n",
    "                    # weigh the pixel value and sum\n",
    "                    weighted_pixel_sum += pixel * weight\n",
    "\n",
    "            # finally, the pixel at location (x,y) is the sum of the weighed neighborhood\n",
    "            filtered[y, x] = weighted_pixel_sum\n",
    "            \n",
    "    if normalize:\n",
    "        filtered = filtered / kernel.sum()\n",
    "        \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import an image using the cv2 package and scale it in the range [0,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITE_LEVEL = 255\n",
    "\n",
    "image = cv2.imread('lena.jpg', cv2.IMREAD_GRAYSCALE).astype(float)\n",
    "image /= WHITE_LEVEL\n",
    "image = cv2.resize(image, (256, 256, ))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use our implementation to do uniform blurring. Try playing with the kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5))\n",
    "filtered_image = my_conv2d(image, kernel, normalize=True)\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see how our function behaves when convolving with an indicator function. Try playing with the indices of the chosen pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.zeros((9, 9))\n",
    "kernel[4, 4] = 1\n",
    "filtered_image = my_conv2d(image, kernel, normalize=True)\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the code we wrote isn't optimal, since it doesn't let you control the padding and it's also quite slow.\n",
    "\n",
    "Convolutions can be implemented efficiently by multiplying with the appropriate sparse circulant matrices.\n",
    "\n",
    "Another efficient way to implment convolution is by using the \"convolution theorem\". As you have seen in the lecture, this theorem states that every convolution is just a point-wise multiplication in the Fourier domain. \n",
    "\n",
    "All the standard libraries in Python use such efficient implementations, so let us now use the convolution operation from our imported libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5))\n",
    "kernel /= kernel.sum()\n",
    "filtered_image = scipy.signal.convolve2d(image, kernel, boundary='symm', mode='same')\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at more realistic kernels, the Gaussian kernels:\n",
    "$$h\\left(x\\right)=\\exp\\left(-x^TAx\\right)$$\n",
    "where $A$ is a PSD matrix.\n",
    "\n",
    "We will usually assume that $A$ is diagonalizable and hence:\n",
    "$$h\\left(x\\right)=\\exp\\left(-\\sum_i\\sigma_ix_i^2\\right)$$\n",
    "\n",
    "Here are a few examples (try playing with values of $\\sigma_i$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(-10, 10, num=30)\n",
    "power = -0.5 * t ** 2\n",
    "gauss_1d = np.exp(power)\n",
    "gauss_1d /= np.sum(gauss_1d)\n",
    "plt.plot(t, power)\n",
    "plt.show()\n",
    "plt.plot(t, gauss_1d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_1d = np.exp(-0.1 * t ** 2)\n",
    "gauss_2d_isotropic = np.outer(gauss_1d, gauss_1d)\n",
    "plt.imshow(gauss_2d_isotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_1d_x = np.exp(-0.1 * t ** 2)\n",
    "gauss_1d_y = np.exp(-0.7 * t ** 2)\n",
    "gauss_2d_anisotropic = np.outer(gauss_1d_y, gauss_1d_x)\n",
    "plt.imshow(gauss_2d_anisotropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare what happens when we convolve with these kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotropic_filtered_image = scipy.signal.convolve2d(image, gauss_2d_isotropic, boundary='symm', mode='same')\n",
    "plt.imshow(isotropic_filtered_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropic_filtered_image = scipy.signal.convolve2d(image, gauss_2d_anisotropic, boundary='symm', mode='same')\n",
    "plt.imshow(anisotropic_filtered_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_anisotropic_filter = np.transpose(gauss_2d_anisotropic)\n",
    "plt.imshow(rotated_anisotropic_filter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_anisotropic_filtered_image = scipy.signal.convolve2d(image, rotated_anisotropic_filter, boundary='symm', mode='same')\n",
    "plt.imshow(rotated_anisotropic_filtered_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, we have only seen the use of convolutions for blurring images, but we can also construct filters for sharpenning them as well.\n",
    "\n",
    "We will start by using an edge detection filter. Convolving an image $ u(x,y) $ with it gives us a numerical estimation of the laplacian of the image $ \\Delta u(x,y)=u_{xx}(x,y)+u_{yy}(x,y) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection_filter = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 4, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "print(edge_detection_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convolve with this filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = scipy.signal.convolve2d(image, edge_detection_filter, mode='same')\n",
    "edges = edges.clip(0, 1)\n",
    "plt.imshow(edges ,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the edges back to the original image to increase the sharpness. Try playing with the value of SHARPEN_FORCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARPEN_FORCE = 0.3\n",
    "sharpened_image = image + SHARPEN_FORCE * edges\n",
    "sharpened_image = sharpened_image.clip(0, 1)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('before')\n",
    "plt.show()\n",
    "plt.imshow(sharpened_image, cmap='gray')\n",
    "plt.title('after')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the diagonal neighboring pixels for detecting edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal_edge_detection_filter = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, 8, -1],\n",
    "    [-1, -1, -1]\n",
    "])\n",
    "\n",
    "print(diagonal_edge_detection_filter)\n",
    "\n",
    "diagonal_edges = scipy.signal.convolve2d(image, diagonal_edge_detection_filter, mode='same')\n",
    "diagonal_edges = diagonal_edges.clip(0, 1)\n",
    "plt.imshow(edges ,cmap='gray')\n",
    "plt.title('edges')\n",
    "plt.show()\n",
    "plt.imshow(diagonal_edges ,cmap='gray')\n",
    "plt.title('diagonal edges')\n",
    "plt.show()\n",
    "\n",
    "SHARPEN_FORCE = 0.3\n",
    "diagonally_sharpened_image = image + SHARPEN_FORCE * diagonal_edges\n",
    "diagonally_sharpened_image = diagonally_sharpened_image.clip(0, 1)\n",
    "\n",
    "plt.imshow(sharpened_image, cmap='gray')\n",
    "plt.title('sharpened')\n",
    "plt.show()\n",
    "plt.imshow(diagonally_sharpened_image, cmap='gray')\n",
    "plt.title('diagonally sharpened')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since convolutoin is a linear opration, we can also sharpen an image by using a single filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARPEN_FORCE = 0.3\n",
    "indicator_filter = np.zeros(edge_detection_filter.shape)\n",
    "indicator_filter[1, 1] = 1\n",
    "sharpen_filter = SHARPEN_FORCE * edge_detection_filter + indicator_filter\n",
    "\n",
    "print('Edge detection filter:')\n",
    "print(edge_detection_filter)\n",
    "print('Indicator filter:')\n",
    "print(indicator_filter)\n",
    "print('Sharpen filter:')\n",
    "print(sharpen_filter)\n",
    "\n",
    "sharpened_image = scipy.signal.convolve2d(image, sharpen_filter, mode='same')\n",
    "sharpened_image = sharpened_image.clip(0, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('before')\n",
    "plt.show()\n",
    "plt.imshow(sharpened_image, cmap='gray')\n",
    "plt.title('after')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we've constructed an anisotropic Gaussian kernel by multiplying two Gaussian kernels with different standard deviations, but realistic blur is not exactly Gaussian (it can be determined by the motion of the camera, for example).\n",
    "\n",
    "Let us see a more general way of constructing kernels. We will use it for constructing Gaussians, but this can be trivially replaced by any other function of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(sample_range, sigma=1):\n",
    "    \"\"\"\n",
    "    creates a gaussian kernel sampled between [-sample_range, sample_range] with a standard deviation of sigma\n",
    "    \"\"\"\n",
    "\n",
    "    ax = np.linspace(-sample_range, sample_range)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "\n",
    "    # 2d gaussian function in our case, but this can be any arbitrary function parametrized by x and y\n",
    "    kernel = np.exp(-(xx ** 2 + yy ** 2) / (2 * sigma **2))\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "kernel = gaussian_kernel(50, sigma=10)\n",
    "plt.imshow(kernel)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
